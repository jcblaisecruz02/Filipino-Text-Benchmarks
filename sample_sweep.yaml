program: train.py
method: random
metric:
  name: Test Loss
  goal: minimize
parameters:
  seed:
    distribution: int_uniform
    min: 1
    max: 9999
  learning_rate:
    value: 2e-4
  weight_decay:
    value: 1e-6
  pretrained:
    value: jcblaise/electra-tagalog-small-cased-discriminator
  train_data:
    value: data/hatespeech/train.csv
  valid_data:
    value: data/hatespeech/valid.csv
  test_data:
    value: data/hatespeech/test.csv
  text_columns:
    value: text
  label_columns:
    value: label
  save_cache:
    value: false
  checkpoint:
    value: model.pt
  do_train:
    value: true
  do_eval:
    value: true
  msl:
    value: 128
  epochs:
    value: 3
  add_token:
    value: '[LINK],[MENTION],[HASHTAG]'
  data_pct:
    value: 1.0
  batch_size:
    value: 32
  warmup_pct:
    value: 0.1
  random_init:
    value: false
  accumulation:
    value: 1
  adam_epsilon:
    value: 1e-6
  use_scheduler:
    value: true
  retokenize_data:
    value: false
  no_cuda:
    value: false
  dont_save:
    value: false
  use_wandb:
    value: true
  wandb_username:
    value: username
  wandb_project_name:
    value: project
